{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec_implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZCfn4XFGp6ox",
        "PftIpNFhqB8J"
      ],
      "authorship_tag": "ABX9TyM3dBhajOgn6RM3uSCqMspI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sibat119/papers-review-code-impl/blob/main/word2vec/word2vec_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFDHHgk4fXuQ"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torch.functional as F\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from collections import Counter\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDKg_FZQpxPU"
      },
      "source": [
        "## **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSFVw39j8u2Y"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "class Word2vecDataset(Dataset):\n",
        "    def __init__(self, datapath, window_size):\n",
        "        self.window_size = window_size\n",
        "        self.sentences_count = 0\n",
        "        self.input_file = open(datapath, encoding=\"utf8\")\n",
        "        self.corpus = self.get_corpus(datapath)\n",
        "        self.words = self.get_words(self.corpus)\n",
        "        self.vocab_to_int, self.int_to_vocab = self.create_lookup_tables(self.words)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.sentences_count\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.sentences_count\n",
        "\n",
        "    @staticmethod\n",
        "    def collate(batches):\n",
        "        all_u = [u for batch in batches for u, _, _ in batch if len(batch) > 0]\n",
        "        all_v = [v for batch in batches for _, v, _ in batch if len(batch) > 0]\n",
        "        all_neg_v = [neg_v for batch in batches for _, _, neg_v in batch if len(batch) > 0]\n",
        "\n",
        "        return torch.LongTensor(all_u), torch.LongTensor(all_v), torch.LongTensor(all_neg_v)\n",
        "    \n",
        "    def get_corpus(self, datapath):\n",
        "        corpus = ''\n",
        "        with open(datapath) as input_file:\n",
        "            data_file = json.load(input_file)\n",
        "            for x in data_file:\n",
        "                self.sentences_count += 1\n",
        "                corpus += (x[\"text\"].lower().strip())\n",
        "        print(len(corpus.strip()))\n",
        "        return corpus\n",
        "  \n",
        "    def get_words(self, text):\n",
        "        # Replace punctuation with tokens so we can use them in our model\n",
        "        text = text.lower()\n",
        "        text = text.replace('.', ' <PERIOD> ')\n",
        "        text = text.replace(',', ' <COMMA> ')\n",
        "        text = text.replace('\"', ' <QUOTATION_MARK> ')\n",
        "        text = text.replace(';', ' <SEMICOLON> ')\n",
        "        text = text.replace('!', ' <EXCLAMATION_MARK> ')\n",
        "        text = text.replace('?', ' <QUESTION_MARK> ')\n",
        "        text = text.replace('(', ' <LEFT_PAREN> ')\n",
        "        text = text.replace(')', ' <RIGHT_PAREN> ')\n",
        "        text = text.replace('--', ' <HYPHENS> ')\n",
        "        text = text.replace('?', ' <QUESTION_MARK> ')\n",
        "        # text = text.replace('\\n', ' <NEW_LINE> ')\n",
        "        text = text.replace(':', ' <COLON> ')\n",
        "        words = text.split()\n",
        "        \n",
        "        # Remove all words with  5 or fewer occurences\n",
        "        word_counts = Counter(words)\n",
        "        trimmed_words = [word for word in words if word_counts[word] > 2]\n",
        "\n",
        "        return trimmed_words\n",
        "\n",
        "    def create_lookup_tables(self, words):\n",
        "        \"\"\"\n",
        "        Create lookup tables for vocabulary\n",
        "        :param words: Input list of words\n",
        "        :return: Two dictionaries, vocab_to_int, int_to_vocab\n",
        "        \"\"\"\n",
        "        word_counts = Counter(words)\n",
        "        # sorting the words from most to least frequent in text occurrence\n",
        "        sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "        # create int_to_vocab dictionaries\n",
        "        int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
        "        vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
        "\n",
        "        return vocab_to_int, int_to_vocab"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PASUmgZp4A_l"
      },
      "source": [
        "\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYWq_Y_Pon7S",
        "outputId": "1409f48c-a7ca-4dbc-c89f-fb84c75f84b6"
      },
      "source": [
        "\n",
        "threshold = 1e-5\n",
        "word_counts = Counter(int_words)\n",
        "#print(list(word_counts.items())[0])  # dictionary of int_words, how many times they appear\n",
        "\n",
        "total_count = len(int_words)\n",
        "freqs = {word: count/total_count for word, count in word_counts.items()}\n",
        "p_drop = {word: 1 - np.sqrt(threshold/freqs[word]) for word in word_counts}\n",
        "# discard some frequent words, according to the subsampling equation\n",
        "# create a new list of words for training\n",
        "train_words = [word for word in int_words if random.random() < (1 - p_drop[word])]\n",
        "\n",
        "print(train_words[:30])\n",
        "print(Counter(train_words))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8, 5, 1, 13]\n",
            "Counter({8: 1, 5: 1, 1: 1, 13: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qP5HMczpHfI"
      },
      "source": [
        "def get_context_words(words, idx, window_size=5):\n",
        "    ''' Get a list of words in a window around an index. '''\n",
        "    \n",
        "    # R = np.random.randint(1, window_size+1)\n",
        "    start = idx - window_size if (idx - window_size) > 0 else 0\n",
        "    stop = idx + window_size\n",
        "    target_words = words[start:idx] + words[idx+1:stop+1]\n",
        "    \n",
        "    return list(target_words)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLpriprIroAP"
      },
      "source": [
        "def neg_sampling(self, vocab):\n",
        "  NEG_SIZE = 1e6\n",
        "  neg_word_list = []\n",
        "  sorted_vocab = []\n",
        "  freq_sum = np.sum(vocab[word]['word_freq']**0.75 for word in vocab)\n",
        "  for word in vocab:\n",
        "      sorted_vocab.append((word, vocab[word]['word_freq']))\n",
        "  sorted_vocab.sort(key=lambda tup: tup[1], reverse=True)\n",
        "  for word in sorted_vocab:\n",
        "      neg_word_list.extend([word[0]] * int((word[1]**0.75 / freq_sum) * NEG_SIZE))\n",
        "  return neg_word_list"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCfn4XFGp6ox"
      },
      "source": [
        "## **Define Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wncXsAjaqUlY"
      },
      "source": [
        "class SkipGramModel(nn.Module):\n",
        "\n",
        "    def __init__(self, emb_size, emb_dimension):\n",
        "        super(SkipGramModel, self).__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.emb_dimension = emb_dimension\n",
        "        self.word_embeddings = nn.Embedding(emb_size, emb_dimension, sparse=True)\n",
        "        self.context_embeddings = nn.Embedding(emb_size, emb_dimension, sparse=True)\n",
        "\n",
        "        initrange = 1.0 / self.emb_dimension\n",
        "        init.uniform_(self.word_embeddings.weight.data, -initrange, initrange)\n",
        "        init.constant_(self.context_embeddings.weight.data, 0)\n",
        "\n",
        "    def forward(self, pos_u, pos_v, neg_v):\n",
        "        emb_u = self.word_embeddings(pos_u)\n",
        "        emb_v = self.context_embeddings(pos_v)\n",
        "        emb_neg_v = self.context_embeddings(neg_v)\n",
        "\n",
        "        score = torch.sum(torch.mul(emb_u, emb_v), dim=1)\n",
        "        score = torch.clamp(score, max=10, min=-10)\n",
        "        score = -F.logsigmoid(score)\n",
        "\n",
        "        neg_score = torch.bmm(emb_neg_v, emb_u.unsqueeze(2)).squeeze()\n",
        "        neg_score = torch.clamp(neg_score, max=10, min=-10)\n",
        "        neg_score = -torch.sum(F.logsigmoid(-neg_score), dim=1)\n",
        "\n",
        "        return torch.mean(score + neg_score)\n",
        "\n",
        "    def save_embedding(self, id2word, file_name):\n",
        "        embedding = self.word_embeddings.weight.cpu().data.numpy()\n",
        "        with open(file_name, 'w') as f:\n",
        "            f.write('%d %d\\n' % (len(id2word), self.emb_dimension))\n",
        "            for wid, w in id2word.items():\n",
        "                e = ' '.join(map(lambda x: str(x), embedding[wid]))\n",
        "                f.write('%s %s\\n' % (w, e))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV9CfmDntUu2"
      },
      "source": [
        ""
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PftIpNFhqB8J"
      },
      "source": [
        "## **Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUyq3l8-qWkm"
      },
      "source": [
        "def train(skip_gram_model, dataloader, initial_lr=1e-5, iterations=3, device='cpu'):\n",
        "  for iteration in range(iterations):\n",
        "\n",
        "      print(\"\\n\\n\\nIteration: \" + str(iteration + 1))\n",
        "      optimizer = optim.SparseAdam(skip_gram_model.parameters(), lr=initial_lr)\n",
        "      scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(dataloader))\n",
        "\n",
        "      running_loss = 0.0\n",
        "      for i, sample_batched in enumerate(tqdm(dataloader)):\n",
        "\n",
        "          if len(sample_batched[0]) > 1:\n",
        "              pos_u = sample_batched[0].to(device)\n",
        "              pos_v = sample_batched[1].to(device)\n",
        "              neg_v = sample_batched[2].to(device)\n",
        "\n",
        "              scheduler.step()\n",
        "              optimizer.zero_grad()\n",
        "              loss = skip_gram_model.forward(pos_u, pos_v, neg_v)\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "              running_loss = running_loss * 0.9 + loss.item() * 0.1\n",
        "              if i > 0 and i % 500 == 0:\n",
        "                  print(\" Loss: \" + str(running_loss))\n",
        "      # skip_gram_model.save_embedding(id2word, output_file_name)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR4Q2cN6qJmE"
      },
      "source": [
        "## **Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEg94x1QqYA7"
      },
      "source": [
        "skip_gram_model = SkipGramModel(len(vocab_to_int), 50)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJtcVndi4ygq",
        "outputId": "58eb9245-a7ee-4646-a250-19490bd6a6a1"
      },
      "source": [
        "dataset = Word2vecDataset('/content/wiki_clean.json', 5)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0, collate_fn=dataset.collate)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33536661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "6K-ROBxv4EDd",
        "outputId": "ced69a3b-28af-4aaa-cb60-6ae9df442569"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train(skip_gram_model=skip_gram_model, dataloader=dataloader, device=device)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Iteration: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/312 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-9c115ccc604b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip_gram_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_gram_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-66-31ce063f7903>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(skip_gram_model, dataloader, initial_lr, iterations, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batched\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_batched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-61-7e5ecd0cf925>\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batches)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mall_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mall_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mall_neg_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mneg_v\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_v\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-7e5ecd0cf925>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mall_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mall_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mall_neg_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mneg_v\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_v\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsdroAz7qOX3"
      },
      "source": [
        "## **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6NQl0Q_qZmR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}